{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ZXYVZs_6o4LCibduxMnUr1YwkRA1ev_6",
      "authorship_tag": "ABX9TyN2sTImDuTRODPYlv01Bt6l",
      "include_colab_link": True

    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JanithRankelum/Air-Pollution-Analysis/blob/janith/Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wnWhyLC7oVl-"
      },
      "outputs": [],
      "source": [
        "# Data Preprocessing with apache spark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Data Loading\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataPreprocessing\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the CSV file into a Spark DataFrame\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/openaq.csv\", header=True, sep=\";\", inferSchema=True)\n",
        "\n",
        "# Show the first few rows of the DataFrame\n",
        "df.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwld1C0no6lf",
        "outputId": "f0354afd-9175-475e-ee06-abc9dc870624"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+--------------------+-------------------+--------------------+---------+-----------+-----+-----------+-------------------+-------------+\n",
            "|Country Code|                City|           Location|         Coordinates|Pollutant|Source Name| Unit|      Value|       Last Updated|Country Label|\n",
            "+------------+--------------------+-------------------+--------------------+---------+-----------+-----+-----------+-------------------+-------------+\n",
            "|          RS|            Belgrade|Belgrade-Stari grad|44.82111999994846...|      NO2|        eea|µg/m³|   44.85432|2024-08-01 07:00:00|       Serbia|\n",
            "|          RS|          Novi Pazar|         Novi Pazar|43.13970399996856...|      SO2|        eea|µg/m³|16.30967665|2024-07-31 07:00:00|       Serbia|\n",
            "|          RS|DROBETA TURNU SEV...|               MH-1|44.62663300021146...|      NO2|        eea|µg/m³|       -1.0|2024-08-01 07:00:00|       Serbia|\n",
            "|          RS|              Vranje|             Vranje|42.55112499985959...|       CO|        eea|µg/m³| 320.017445|2024-07-31 07:00:00|       Serbia|\n",
            "|          RS|         Bor Krivelj|        Bor Krivelj|44.137878, 22.093133|      SO2|     serbia|µg/m³|  11.789101|2024-07-31 07:00:00|       Serbia|\n",
            "+------------+--------------------+-------------------+--------------------+---------+-----------+-----+-----------+-------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Data Cleansing\n",
        "# Check for missing values\n",
        "\n",
        "from pyspark.sql.functions import col, count, when\n",
        "\n",
        "# Check for missing values\n",
        "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()\n",
        "\n",
        "# Drop rows with missing values in critical columns\n",
        "df_cleaned = df.na.drop(subset=[\"Value\", \"Last Updated\"])\n",
        "\n",
        "# Remove duplicate rows\n",
        "df_cleaned = df_cleaned.dropDuplicates()\n",
        "\n",
        "# Show the cleaned DataFrame\n",
        "df_cleaned.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9OYLRWlpKBt",
        "outputId": "a13c1074-6b01-465a-c239-6d3e80229742"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+--------+-----------+---------+-----------+----+-----+------------+-------------+\n",
            "|Country Code| City|Location|Coordinates|Pollutant|Source Name|Unit|Value|Last Updated|Country Label|\n",
            "+------------+-----+--------+-----------+---------+-----------+----+-----+------------+-------------+\n",
            "|           0|28538|       0|         70|        0|          0|   0|    0|           0|          127|\n",
            "+------------+-----+--------+-----------+---------+-----------+----+-----+------------+-------------+\n",
            "\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+\n",
            "|Country Code|           City|            Location|         Coordinates|Pollutant|   Source Name| Unit|   Value|       Last Updated|Country Label|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+\n",
            "|          TR|           Uşak|         Uşak (Yeni)|38.6639258113343,...|       CO|       Turkiye|µg/m³|1373.504|2023-05-31 00:00:00|       Turkey|\n",
            "|          ES|       Asturias|             ES0008R|43.4391699994639,...|       NO|     EEA Spain|µg/m³|    0.64|2024-01-16 00:00:00|        Spain|\n",
            "|          AT|3100 St. Pölten|St. Pölten Eybner...|48.21160000001331...|       O3|           eea|µg/m³|   5.887|2025-01-31 08:00:00|      Austria|\n",
            "|          MX|    Corregidora|         Corregidora|20.552563888889, ...|       O3|Sinaica Mexico|  ppm| 0.01977|2025-01-30 08:00:00|       Mexico|\n",
            "|          US|    NORTH SLOPE|        BLM-Kaktovik|  70.1319, -143.6239|     PM10|        AirNow|µg/m³|    47.0|2023-05-30 20:00:00|United States|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Data Transformation\n",
        "\n",
        "from pyspark.sql.functions import col, to_timestamp, year, mean, stddev\n",
        "\n",
        "# Convert 'Last Updated' column to timestamp\n",
        "df_transformed = df_cleaned.withColumn(\"Last Updated\", to_timestamp(col(\"Last Updated\")))\n",
        "\n",
        "# Create a new feature: Year from 'Last Updated'\n",
        "df_transformed = df_transformed.withColumn(\"Year\", year(col(\"Last Updated\")))\n",
        "\n",
        "# Compute mean and standard deviation for normalization\n",
        "stats = df_transformed.select(mean(col(\"Value\")).alias(\"mean\"), stddev(col(\"Value\")).alias(\"stddev\")).collect()[0]\n",
        "mean_value, stddev_value = stats[\"mean\"], stats[\"stddev\"]\n",
        "\n",
        "# Ensure stddev is not zero to avoid division errors\n",
        "if stddev_value and stddev_value != 0:\n",
        "    df_transformed = df_transformed.withColumn(\"Value_Normalized\", (col(\"Value\") - mean_value) / stddev_value)\n",
        "else:\n",
        "    df_transformed = df_transformed.withColumn(\"Value_Normalized\", col(\"Value\"))\n",
        "\n",
        "# Show the transformed DataFrame\n",
        "df_transformed.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Ez-tappcs2",
        "outputId": "a9a781ba-5651-46f5-f99e-9aa9a96ef8d9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+\n",
            "|Country Code|           City|            Location|         Coordinates|Pollutant|   Source Name| Unit|   Value|       Last Updated|Country Label|Year|    Value_Normalized|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+\n",
            "|          TR|           Uşak|         Uşak (Yeni)|38.6639258113343,...|       CO|       Turkiye|µg/m³|1373.504|2023-05-31 00:00:00|       Turkey|2023|0.029000433850905845|\n",
            "|          ES|       Asturias|             ES0008R|43.4391699994639,...|       NO|     EEA Spain|µg/m³|    0.64|2024-01-16 00:00:00|        Spain|2024|-0.02078703539679573|\n",
            "|          AT|3100 St. Pölten|St. Pölten Eybner...|48.21160000001331...|       O3|           eea|µg/m³|   5.887|2025-01-31 08:00:00|      Austria|2025|-0.02059675081569...|\n",
            "|          MX|    Corregidora|         Corregidora|20.552563888889, ...|       O3|Sinaica Mexico|  ppm| 0.01977|2025-01-30 08:00:00|       Mexico|2025|-0.02080952828906...|\n",
            "|          US|    NORTH SLOPE|        BLM-Kaktovik|  70.1319, -143.6239|     PM10|        AirNow|µg/m³|    47.0|2023-05-30 20:00:00|United States|2023|-0.01910577121161537|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Feature Engineering\n",
        "from pyspark.sql.functions import when\n",
        "\n",
        "# Create a new feature: Pollutant Category based on 'Pollutant'\n",
        "df_transformed = df_transformed.withColumn(\n",
        "    \"Pollutant_Category\",\n",
        "    when(col(\"Pollutant\").isin([\"NO2\", \"SO2\"]), \"Gas\")\n",
        "    .when(col(\"Pollutant\").isin([\"PM2.5\", \"PM10\"]), \"Particulate\")\n",
        "    .otherwise(\"Other\")\n",
        ")\n",
        "\n",
        "# Show the DataFrame with new features\n",
        "df_transformed.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpOVwinEqjwR",
        "outputId": "3d024d30-2738-4920-dd80-74a961a90aff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+------------------+\n",
            "|Country Code|           City|            Location|         Coordinates|Pollutant|   Source Name| Unit|   Value|       Last Updated|Country Label|Year|    Value_Normalized|Pollutant_Category|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+------------------+\n",
            "|          TR|           Uşak|         Uşak (Yeni)|38.6639258113343,...|       CO|       Turkiye|µg/m³|1373.504|2023-05-31 00:00:00|       Turkey|2023|0.029000433850905845|             Other|\n",
            "|          ES|       Asturias|             ES0008R|43.4391699994639,...|       NO|     EEA Spain|µg/m³|    0.64|2024-01-16 00:00:00|        Spain|2024|-0.02078703539679573|             Other|\n",
            "|          AT|3100 St. Pölten|St. Pölten Eybner...|48.21160000001331...|       O3|           eea|µg/m³|   5.887|2025-01-31 08:00:00|      Austria|2025|-0.02059675081569...|             Other|\n",
            "|          MX|    Corregidora|         Corregidora|20.552563888889, ...|       O3|Sinaica Mexico|  ppm| 0.01977|2025-01-30 08:00:00|       Mexico|2025|-0.02080952828906...|             Other|\n",
            "|          US|    NORTH SLOPE|        BLM-Kaktovik|  70.1319, -143.6239|     PM10|        AirNow|µg/m³|    47.0|2023-05-30 20:00:00|United States|2023|-0.01910577121161537|       Particulate|\n",
            "+------------+---------------+--------------------+--------------------+---------+--------------+-----+--------+-------------------+-------------+----+--------------------+------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Comparison with pandas\n",
        "import pandas as pd\n",
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, to_timestamp, year, mean, stddev, when, count, isnan\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataPreprocessing\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Load the CSV file into a Spark DataFrame\n",
        "start_time = time.time()\n",
        "df_spark = spark.read.csv(\"/content/drive/MyDrive/openaq.csv\", header=True, sep=\";\", inferSchema=True)\n",
        "print(f\"Spark Loading Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Data Cleansing\n",
        "start_time = time.time()\n",
        "df_spark_cleaned = df_spark.na.drop(subset=[\"Value\", \"Last Updated\"]).dropDuplicates()\n",
        "df_spark_cleaned.cache()  # Cache for better performance\n",
        "print(f\"Spark Cleansing Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Data Transformation\n",
        "start_time = time.time()\n",
        "df_spark_cleaned = df_spark_cleaned.withColumn(\"Last Updated\", to_timestamp(col(\"Last Updated\")))\n",
        "df_spark_cleaned = df_spark_cleaned.withColumn(\"Year\", year(col(\"Last Updated\")))\n",
        "\n",
        "# Compute mean and stddev safely\n",
        "stats = df_spark_cleaned.select(mean(col(\"Value\")).alias(\"mean\"), stddev(col(\"Value\")).alias(\"stddev\")).collect()[0]\n",
        "mean_value, stddev_value = stats[\"mean\"], stats[\"stddev\"]\n",
        "\n",
        "# Ensure stddev is not zero to prevent division errors\n",
        "if stddev_value and stddev_value != 0:\n",
        "    df_spark_cleaned = df_spark_cleaned.withColumn(\"Value_Normalized\", (col(\"Value\") - mean_value) / stddev_value)\n",
        "else:\n",
        "    df_spark_cleaned = df_spark_cleaned.withColumn(\"Value_Normalized\", col(\"Value\"))\n",
        "\n",
        "print(f\"Spark Transformation Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Feature Engineering\n",
        "start_time = time.time()\n",
        "df_spark_cleaned = df_spark_cleaned.withColumn(\n",
        "    \"Pollutant_Category\",\n",
        "    when(col(\"Pollutant\").isin([\"NO2\", \"SO2\"]), \"Gas\")\n",
        "    .when(col(\"Pollutant\").isin([\"PM2.5\", \"PM10\"]), \"Particulate\")\n",
        "    .otherwise(\"Other\")\n",
        ")\n",
        "print(f\"Spark Feature Engineering Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Stop Spark session\n",
        "spark.stop()\n",
        "\n",
        "# Pandas Processing\n",
        "# Load the CSV file into a Pandas DataFrame\n",
        "start_time = time.time()\n",
        "df_pandas = pd.read_csv(\"/content/drive/MyDrive/openaq.csv\", sep=\";\")\n",
        "print(f\"Pandas Loading Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Data Cleansing\n",
        "start_time = time.time()\n",
        "df_pandas_cleaned = df_pandas.dropna(subset=[\"Value\", \"Last Updated\"]).drop_duplicates()\n",
        "print(f\"Pandas Cleansing Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Data Transformation\n",
        "start_time = time.time()\n",
        "df_pandas_cleaned[\"Last Updated\"] = pd.to_datetime(df_pandas_cleaned[\"Last Updated\"])\n",
        "df_pandas_cleaned[\"Year\"] = df_pandas_cleaned[\"Last Updated\"].dt.year\n",
        "\n",
        "# Compute mean and stddev safely\n",
        "mean_value_pandas = df_pandas_cleaned[\"Value\"].mean()\n",
        "stddev_value_pandas = df_pandas_cleaned[\"Value\"].std()\n",
        "\n",
        "# Handle stddev == 0 case\n",
        "if stddev_value_pandas and stddev_value_pandas != 0:\n",
        "    df_pandas_cleaned[\"Value_Normalized\"] = (df_pandas_cleaned[\"Value\"] - mean_value_pandas) / stddev_value_pandas\n",
        "else:\n",
        "    df_pandas_cleaned[\"Value_Normalized\"] = df_pandas_cleaned[\"Value\"]\n",
        "\n",
        "print(f\"Pandas Transformation Time: {time.time() - start_time:.4f} seconds\")\n",
        "\n",
        "# Feature Engineering\n",
        "start_time = time.time()\n",
        "df_pandas_cleaned[\"Pollutant_Category\"] = df_pandas_cleaned[\"Pollutant\"].apply(\n",
        "    lambda x: \"Gas\" if x in [\"NO2\", \"SO2\"] else (\"Particulate\" if x in [\"PM2.5\", \"PM10\"] else \"Other\")\n",
        ")\n",
        "print(f\"Pandas Feature Engineering Time: {time.time() - start_time:.4f} seconds\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfdv6rn6qqRw",
        "outputId": "ea4d580d-b15d-4186-d443-737ee5db206f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark Loading Time: 1.1044 seconds\n",
            "Spark Cleansing Time: 0.1137 seconds\n",
            "Spark Transformation Time: 10.6520 seconds\n",
            "Spark Feature Engineering Time: 0.0413 seconds\n",
            "Pandas Loading Time: 0.1790 seconds\n",
            "Pandas Cleansing Time: 0.0717 seconds\n",
            "Pandas Transformation Time: 0.0432 seconds\n",
            "Pandas Feature Engineering Time: 0.0109 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import threading\n",
        "import requests\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "from pyspark.sql.functions import col, mean, max, min, to_timestamp\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RealTimeAnalytics\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Define API URL\n",
        "API_URL = \"https://public.opendatasoft.com//api/explore/v2.1/catalog/datasets/openaq/records?select=*&where=%22sri%20lanka%22&limit=20&lang=en\"\n",
        "\n",
        "# Define Schema for the DataFrame\n",
        "schema = StructType([\n",
        "    StructField(\"country\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"location\", StringType(), True),\n",
        "    StructField(\"lon\", DoubleType(), True),\n",
        "    StructField(\"lat\", DoubleType(), True),\n",
        "    StructField(\"measurements_parameter\", StringType(), True),\n",
        "    StructField(\"measurements_sourcename\", StringType(), True),\n",
        "    StructField(\"measurements_unit\", StringType(), True),\n",
        "    StructField(\"measurements_value\", DoubleType(), True),\n",
        "    StructField(\"measurements_lastupdated\", StringType(), True),\n",
        "    StructField(\"country_name_en\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create an empty DataFrame with the defined schema\n",
        "df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
        "\n",
        "# Function to fetch API data\n",
        "def fetch_api_data():\n",
        "    response = requests.get(API_URL)\n",
        "    if response.status_code == 200:\n",
        "        raw_data = response.json().get(\"results\", [])\n",
        "\n",
        "        # Extract and format the required fields\n",
        "        formatted_data = [\n",
        "            {\n",
        "                \"country\": item.get(\"country\"),\n",
        "                \"city\": item.get(\"city\", \"Unknown\"),  # Handle missing city\n",
        "                \"location\": item.get(\"location\"),\n",
        "                \"lon\": item.get(\"coordinates\", {}).get(\"lon\"),\n",
        "                \"lat\": item.get(\"coordinates\", {}).get(\"lat\"),\n",
        "                \"measurements_parameter\": item.get(\"measurements_parameter\"),\n",
        "                \"measurements_sourcename\": item.get(\"measurements_sourcename\"),\n",
        "                \"measurements_unit\": item.get(\"measurements_unit\"),\n",
        "                \"measurements_value\": item.get(\"measurements_value\"),\n",
        "                \"measurements_lastupdated\": item.get(\"measurements_lastupdated\"),\n",
        "                \"country_name_en\": item.get(\"country_name_en\")\n",
        "            }\n",
        "            for item in raw_data\n",
        "        ]\n",
        "\n",
        "        return formatted_data\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "# Function to update DataFrame with new API data every 10 seconds\n",
        "def update_dataframe():\n",
        "    global df\n",
        "    while True:\n",
        "        # Fetch new data from API\n",
        "        new_data = fetch_api_data()\n",
        "\n",
        "        if new_data:\n",
        "            # Convert new API data to a Spark DataFrame\n",
        "            new_df = spark.createDataFrame(new_data, schema=schema)\n",
        "\n",
        "            # Convert 'measurements_lastupdated' to TimestampType\n",
        "            new_df = new_df.withColumn(\"measurements_lastupdated\", to_timestamp(col(\"measurements_lastupdated\")))\n",
        "\n",
        "            # Append new data to the existing DataFrame\n",
        "            df = df.union(new_df)\n",
        "\n",
        "            # Show the latest data\n",
        "            print(\"\\n🔄 Latest Incoming Data:\")\n",
        "            df.show(truncate=False)\n",
        "\n",
        "            # Compute summary statistics\n",
        "            summary = df.select(\n",
        "                mean(\"measurements_value\").alias(\"mean_value\"),\n",
        "                max(\"measurements_value\").alias(\"max_value\"),\n",
        "                min(\"measurements_value\").alias(\"min_value\")\n",
        "            ).collect()[0]\n",
        "\n",
        "            print(\"\\n📊 Summary Statistics:\")\n",
        "            print(f\"Mean Value: {summary['mean_value']}\")\n",
        "            print(f\"Max Value: {summary['max_value']}\")\n",
        "            print(f\"Min Value: {summary['min_value']}\")\n",
        "\n",
        "            # Detect anomalies (e.g., values above a threshold)\n",
        "            threshold = 100  # Example threshold\n",
        "            anomalies = df.filter(col(\"measurements_value\") > threshold)\n",
        "\n",
        "            if anomalies.count() > 0:\n",
        "                print(\"\\n🚨 Anomalies Detected:\")\n",
        "                anomalies.show(truncate=False)\n",
        "\n",
        "        time.sleep(10)  # Fetch new data every 10 seconds\n",
        "\n",
        "# Run the update function in a separate thread\n",
        "thread = threading.Thread(target=update_dataframe, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Keep the Spark application running\n",
        "while True:\n",
        "    time.sleep(60)  # Keep alive\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "RYKkLNmuq71_",
        "outputId": "50e5c2b7-4798-4bd2-bea4-ba0b556abb86"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "🔄 Latest Incoming Data:\n",
            "+-------+-------+---------------------------+---------+--------+----------------------+-----------------------+-----------------+------------------+------------------------+---------------+\n",
            "|country|city   |location                   |lon      |lat     |measurements_parameter|measurements_sourcename|measurements_unit|measurements_value|measurements_lastupdated|country_name_en|\n",
            "+-------+-------+---------------------------+---------+--------+----------------------+-----------------------+-----------------+------------------+------------------------+---------------+\n",
            "|LK     |Colombo|US Diplomatic Post: Colombo|79.848684|6.913253|PM2.5                 |StateAir_Colombo       |µg/m³            |-999.0            |2025-01-31 08:30:00     |Sri Lanka      |\n",
            "|LK     |N/A    |Colombo                    |79.875341|6.909445|PM2.5                 |AirNow                 |µg/m³            |10.0              |2025-01-31 08:30:00     |Sri Lanka      |\n",
            "+-------+-------+---------------------------+---------+--------+----------------------+-----------------------+-----------------+------------------+------------------------+---------------+\n",
            "\n",
            "\n",
            "📊 Summary Statistics:\n",
            "Mean Value: -494.5\n",
            "Max Value: 10.0\n",
            "Min Value: -999.0\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-14b9c70fbefa>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[0;31m# Keep the Spark application running\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Keep alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pyspark/context.py\u001b[0m in \u001b[0;36msignal_handler\u001b[0;34m(signal, frame)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0msignal_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mNoReturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancelAllJobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# see http://stackoverflow.com/questions/23206787/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit pyngrok requests pyspark\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ruVEixVPY-Ym",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7553843-b50e-4e78-b27d-34e3d799ed88"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.43.2)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.1.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.25.6)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.12.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.30.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.23.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ngrok authtoken 2uWwu1TdwIzAHbG2k9Hq1QYmnDi_3wdNR88knSX1MWqZs34XU\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_Q0LHUba3yY",
        "outputId": "9081197f-34c2-4253-e57b-0a8dbdeedcea"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import time\n",
        "import threading\n",
        "import requests\n",
        "import streamlit as st\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "from pyspark.sql.functions import col, mean, max, min, to_timestamp\n",
        "\n",
        "# Initialize Spark session\n",
        "spark = SparkSession.builder.appName(\"RealTimeAnalytics\").getOrCreate()\n",
        "\n",
        "# API URL\n",
        "API_URL = \"https://public.opendatasoft.com/api/explore/v2.1/catalog/datasets/openaq/records?limit=20\"\n",
        "\n",
        "# Define Schema\n",
        "schema = StructType([\n",
        "    StructField(\"country\", StringType(), True),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"location\", StringType(), True),\n",
        "    StructField(\"lon\", DoubleType(), True),\n",
        "    StructField(\"lat\", DoubleType(), True),\n",
        "    StructField(\"measurements_parameter\", StringType(), True),\n",
        "    StructField(\"measurements_sourcename\", StringType(), True),\n",
        "    StructField(\"measurements_unit\", StringType(), True),\n",
        "    StructField(\"measurements_value\", DoubleType(), True),\n",
        "    StructField(\"measurements_lastupdated\", StringType(), True),\n",
        "    StructField(\"country_name_en\", StringType(), True)\n",
        "])\n",
        "\n",
        "# Create empty DataFrame\n",
        "df = spark.createDataFrame(spark.sparkContext.emptyRDD(), schema)\n",
        "\n",
        "# Function to fetch API data\n",
        "def fetch_api_data():\n",
        "    response = requests.get(API_URL)\n",
        "    if response.status_code == 200:\n",
        "        raw_data = response.json().get(\"results\", [])\n",
        "        formatted_data = [\n",
        "            {\n",
        "                \"country\": item.get(\"country\"),\n",
        "                \"city\": item.get(\"city\", \"Unknown\"),\n",
        "                \"location\": item.get(\"location\"),\n",
        "                \"lon\": item.get(\"coordinates\", {}).get(\"lon\"),\n",
        "                \"lat\": item.get(\"coordinates\", {}).get(\"lat\"),\n",
        "                \"measurements_parameter\": item.get(\"measurements_parameter\"),\n",
        "                \"measurements_sourcename\": item.get(\"measurements_sourcename\"),\n",
        "                \"measurements_unit\": item.get(\"measurements_unit\"),\n",
        "                \"measurements_value\": item.get(\"measurements_value\"),\n",
        "                \"measurements_lastupdated\": item.get(\"measurements_lastupdated\"),\n",
        "                \"country_name_en\": item.get(\"country_name_en\")\n",
        "            }\n",
        "            for item in raw_data\n",
        "        ]\n",
        "        return formatted_data\n",
        "    return []\n",
        "\n",
        "# Streamlit UI\n",
        "st.title(\"🌍 Real-Time Air Quality Dashboard\")\n",
        "st.write(\"Fetching live air quality data...\")\n",
        "\n",
        "# Fetch Data\n",
        "new_data = fetch_api_data()\n",
        "if new_data:\n",
        "    new_df = spark.createDataFrame(new_data, schema=schema)\n",
        "    new_df = new_df.withColumn(\"measurements_lastupdated\", to_timestamp(col(\"measurements_lastupdated\")))\n",
        "\n",
        "    global df\n",
        "    df = df.union(new_df)\n",
        "\n",
        "    # Show Latest Data\n",
        "    st.subheader(\"📊 Latest Data\")\n",
        "    st.dataframe(df.toPandas())\n",
        "\n",
        "    # Summary Statistics\n",
        "    summary = df.select(\n",
        "        mean(\"measurements_value\").alias(\"mean_value\"),\n",
        "        max(\"measurements_value\").alias(\"max_value\"),\n",
        "        min(\"measurements_value\").alias(\"min_value\")\n",
        "    ).collect()[0]\n",
        "\n",
        "    st.subheader(\"📈 Summary Statistics\")\n",
        "    st.write(f\"**Mean Value:** {summary['mean_value']}\")\n",
        "    st.write(f\"**Max Value:** {summary['max_value']}\")\n",
        "    st.write(f\"**Min Value:** {summary['min_value']}\")\n",
        "\n",
        "    # Detect Anomalies\n",
        "    threshold = 100\n",
        "    anomalies = df.filter(col(\"measurements_value\") > threshold)\n",
        "\n",
        "    if anomalies.count() > 0:\n",
        "        st.subheader(\"🚨 Anomalies Detected\")\n",
        "        st.dataframe(anomalies.toPandas())\n",
        "\n",
        "st.write(\"🔄 Auto-updating every 10 seconds...\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ji799tqsn_sh",
        "outputId": "59c0100f-9331-4e80-ff18-b950a3c478fa"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -g localtunnel\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iflTIVtBznWk",
        "outputId": "aaf4229b-3aff-465a-9529-024cd3e5e696"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📊 Summary Statistics:\n",
            "Mean Value: 2.4051899999999966\n",
            "Max Value: 26.0\n",
            "Min Value: 0.001\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|country|city|location|lon               |lat               |measurements_parameter|measurements_sourcename|measurements_unit|measurements_value|measurements_lastupdated|country_name_en   |\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |CO                    |korea-air              |ppm              |0.47              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |O3                    |korea-air              |ppm              |0.0428            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|학장동  |128.979342        |35.154292         |SO2                   |korea-air              |ppm              |0.001             |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보람동  |127.292417        |36.479917         |PM10                  |korea-air              |µg/m³            |13.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|금천구  |126.90833299999998|37.452386         |O3                    |korea-air              |ppm              |0.0361            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|선단동  |127.15920000000001|37.8535           |NO2                   |korea-air              |ppm              |0.0054            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |O3                    |korea-air              |ppm              |0.0492            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |CO                    |korea-air              |ppm              |0.35              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|덕신리  |129.30651         |35.43445          |SO2                   |korea-air              |ppm              |0.0023            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|대광동  |128.13703609999996|36.1439851        |NO2                   |korea-air              |ppm              |0.0065            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|정왕동  |126.7401          |37.3468           |NO2                   |korea-air              |ppm              |0.0072            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|부림동  |126.956859        |37.394327         |PM10                  |korea-air              |µg/m³            |26.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|신풍동  |127.01047199999998|37.283798         |O3                    |korea-air              |ppm              |0.0332            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|진례면  |128.75029500000002|35.245937         |PM10                  |korea-air              |µg/m³            |8.0               |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보은읍  |127.729903        |36.484771         |NO2                   |korea-air              |ppm              |0.0067            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|안성면  |127.65442899999998|35.860351         |NO2                   |korea-air              |ppm              |0.0025            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|강변북로|127.04094299999998|37.539283000000005|O3                    |korea-air              |ppm              |0.0282            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |SO2                   |korea-air              |ppm              |0.0021            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |NO2                   |korea-air              |ppm              |0.0217            |2024-04-12 22:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|영광읍  |126.51199369999999|35.2779955        |O3                    |korea-air              |ppm              |0.0389            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "changed 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8080\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzR3ounaNOdh",
        "outputId": "7a4e8148-eb7a-411d-a635-24b9f13b0d07"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.147.125.189:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0Kyour url is: https://fruity-rockets-turn.loca.lt\n",
            "\n",
            "📊 Summary Statistics:\n",
            "Mean Value: 2.4051899999999975\n",
            "Max Value: 26.0\n",
            "Min Value: 0.001\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|country|city|location|lon               |lat               |measurements_parameter|measurements_sourcename|measurements_unit|measurements_value|measurements_lastupdated|country_name_en   |\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |CO                    |korea-air              |ppm              |0.47              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |O3                    |korea-air              |ppm              |0.0428            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|학장동  |128.979342        |35.154292         |SO2                   |korea-air              |ppm              |0.001             |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보람동  |127.292417        |36.479917         |PM10                  |korea-air              |µg/m³            |13.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|금천구  |126.90833299999998|37.452386         |O3                    |korea-air              |ppm              |0.0361            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|선단동  |127.15920000000001|37.8535           |NO2                   |korea-air              |ppm              |0.0054            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |O3                    |korea-air              |ppm              |0.0492            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |CO                    |korea-air              |ppm              |0.35              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|덕신리  |129.30651         |35.43445          |SO2                   |korea-air              |ppm              |0.0023            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|대광동  |128.13703609999996|36.1439851        |NO2                   |korea-air              |ppm              |0.0065            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|정왕동  |126.7401          |37.3468           |NO2                   |korea-air              |ppm              |0.0072            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|부림동  |126.956859        |37.394327         |PM10                  |korea-air              |µg/m³            |26.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|신풍동  |127.01047199999998|37.283798         |O3                    |korea-air              |ppm              |0.0332            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|진례면  |128.75029500000002|35.245937         |PM10                  |korea-air              |µg/m³            |8.0               |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보은읍  |127.729903        |36.484771         |NO2                   |korea-air              |ppm              |0.0067            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|안성면  |127.65442899999998|35.860351         |NO2                   |korea-air              |ppm              |0.0025            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|강변북로|127.04094299999998|37.539283000000005|O3                    |korea-air              |ppm              |0.0282            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |SO2                   |korea-air              |ppm              |0.0021            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |NO2                   |korea-air              |ppm              |0.0217            |2024-04-12 22:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|영광읍  |126.51199369999999|35.2779955        |O3                    |korea-air              |ppm              |0.0389            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "🔄 Latest Incoming Data:\n",
            "\n",
            "📊 Summary Statistics:\n",
            "Mean Value: 2.4051900000000046\n",
            "Max Value: 26.0\n",
            "Min Value: 0.001\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|country|city|location|lon               |lat               |measurements_parameter|measurements_sourcename|measurements_unit|measurements_value|measurements_lastupdated|country_name_en   |\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |CO                    |korea-air              |ppm              |0.47              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |O3                    |korea-air              |ppm              |0.0428            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|학장동  |128.979342        |35.154292         |SO2                   |korea-air              |ppm              |0.001             |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보람동  |127.292417        |36.479917         |PM10                  |korea-air              |µg/m³            |13.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|금천구  |126.90833299999998|37.452386         |O3                    |korea-air              |ppm              |0.0361            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|선단동  |127.15920000000001|37.8535           |NO2                   |korea-air              |ppm              |0.0054            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |O3                    |korea-air              |ppm              |0.0492            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |CO                    |korea-air              |ppm              |0.35              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|덕신리  |129.30651         |35.43445          |SO2                   |korea-air              |ppm              |0.0023            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|대광동  |128.13703609999996|36.1439851        |NO2                   |korea-air              |ppm              |0.0065            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|정왕동  |126.7401          |37.3468           |NO2                   |korea-air              |ppm              |0.0072            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|부림동  |126.956859        |37.394327         |PM10                  |korea-air              |µg/m³            |26.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|신풍동  |127.01047199999998|37.283798         |O3                    |korea-air              |ppm              |0.0332            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|진례면  |128.75029500000002|35.245937         |PM10                  |korea-air              |µg/m³            |8.0               |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보은읍  |127.729903        |36.484771         |NO2                   |korea-air              |ppm              |0.0067            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|안성면  |127.65442899999998|35.860351         |NO2                   |korea-air              |ppm              |0.0025            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|강변북로|127.04094299999998|37.539283000000005|O3                    |korea-air              |ppm              |0.0282            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |SO2                   |korea-air              |ppm              |0.0021            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |NO2                   |korea-air              |ppm              |0.0217            |2024-04-12 22:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|영광읍  |126.51199369999999|35.2779955        |O3                    |korea-air              |ppm              |0.0389            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "🔄 Latest Incoming Data:\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|country|city|location|lon               |lat               |measurements_parameter|measurements_sourcename|measurements_unit|measurements_value|measurements_lastupdated|country_name_en   |\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |CO                    |korea-air              |ppm              |0.47              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|문창동  |127.437778        |36.316111         |O3                    |korea-air              |ppm              |0.0428            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|학장동  |128.979342        |35.154292         |SO2                   |korea-air              |ppm              |0.001             |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보람동  |127.292417        |36.479917         |PM10                  |korea-air              |µg/m³            |13.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|금천구  |126.90833299999998|37.452386         |O3                    |korea-air              |ppm              |0.0361            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|선단동  |127.15920000000001|37.8535           |NO2                   |korea-air              |ppm              |0.0054            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |O3                    |korea-air              |ppm              |0.0492            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|청계동  |127.1194          |37.19650000000001 |CO                    |korea-air              |ppm              |0.35              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|덕신리  |129.30651         |35.43445          |SO2                   |korea-air              |ppm              |0.0023            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|대광동  |128.13703609999996|36.1439851        |NO2                   |korea-air              |ppm              |0.0065            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|정왕동  |126.7401          |37.3468           |NO2                   |korea-air              |ppm              |0.0072            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|부림동  |126.956859        |37.394327         |PM10                  |korea-air              |µg/m³            |26.0              |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|신풍동  |127.01047199999998|37.283798         |O3                    |korea-air              |ppm              |0.0332            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|진례면  |128.75029500000002|35.245937         |PM10                  |korea-air              |µg/m³            |8.0               |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|보은읍  |127.729903        |36.484771         |NO2                   |korea-air              |ppm              |0.0067            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|안성면  |127.65442899999998|35.860351         |NO2                   |korea-air              |ppm              |0.0025            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|강변북로|127.04094299999998|37.539283000000005|O3                    |korea-air              |ppm              |0.0282            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |SO2                   |korea-air              |ppm              |0.0021            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|효자동  |127.095423        |35.798146         |NO2                   |korea-air              |ppm              |0.0217            |2024-04-12 22:00:00     |Korea, Republic of|\n",
            "|KR     |NULL|영광읍  |126.51199369999999|35.2779955        |O3                    |korea-air              |ppm              |0.0389            |2025-01-28 09:00:00     |Korea, Republic of|\n",
            "+-------+----+--------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------------+------------------+\n",
            "only showing top 20 rows\n",
            "\n",
            "\n",
            "📊 Summary Statistics:\n",
            "Mean Value: 2.40519000000001\n",
            "Max Value: 26.0\n",
            "Min Value: 0.001\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xq9rp7pNRvLf",
        "outputId": "9fdea39d-fcad-4f5f-acb5-5d9d81a4b67c"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "app.py  \u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ohbV-YAWtTV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
